#!/usr/bin/env python3


import hashlib
import itertools
import argparse
import shutil
from pathlib import Path
import os
import subprocess
import hashlib
# import lief # TODO
import time
import pandas as pd
import multiprocessing as mp
import resource
import re
import math
import random


CACHE_DIR = os.path.expanduser('~/.cache/fpvm')
SCRIPT_DIR = Path(os.path.realpath(os.path.dirname(__file__)))
FPVM_HOME = SCRIPT_DIR / '../' # TODO: this FPVM_HOME thing makes distribution later really annoying
FPVM_ARCH = os.getenv("ARCH",default="x64")

# First, attempt to find where FPVM is.
FPVM_LOCATION = None



# TODO: these metrics should be changed to match the real world.
HW_TO_KERNEL_TIME=1000
KERNEL_TO_USER_TIME=1000
CALL_WRAP_TIME=40


# Roquefort Numbers:
HW_TO_KERNEL_TIME=200 # cycles
KERNEL_TO_USER_TIME=1950 # cycles for SIGFPE, 478 for kernel module
# call wrap at 40 or 50   (this should be the cost of a double indirect call, I think, which I have not measured yet)

# on roquefort
KERNEL_TO_USER_TIME=5889


fpvm_locations = [
    # Currently, only look in a few locations.

    # When developing...
    FPVM_HOME / 'build/fpvm.so',

    # When installed to $DIR, $DIR/bin and $DIR/lib are next to eachother, as is the case in nix
    FPVM_HOME / 'lib/fpvm.so',
]

for loc in fpvm_locations:
    loc = os.path.realpath(os.path.expanduser(loc))
    if os.path.isfile(loc):
        FPVM_LOCATION = str(Path(loc).resolve())
        break


# Expand a binary path using PATH
def path_expand(binary):
  bin = shutil.which(binary)

  if bin is None:
    print(f'Could not find binary, {binary}')
    exit(-1)
  return bin




# The point of this class is to provide a way to get a temporary directory
# which is keyed to the content hash of input files or strings
class ContentHashDir:
  def __init__(self, name):
    self._hash = hashlib.sha1()
    self._name = name

  def file_input(self, path):
    self.string_input(f'FILE: {path}') # Just record that we hash a file
    with open(path, "rb") as f:
      # Read the file in chunks to avoid loading the entire file into memory
      chunk = 0
      while chunk := f.read(4096):
          self._hash.update(chunk)


  def string_input(self, s: str):
    self._hash.update(s.encode())


  def digest(self):
    return self._hash.hexdigest()

  # Create the directory on disk, and return a Path to it.
  def get(self, file=None):
    hash = self.digest()
    dir = os.path.expanduser(f'{CACHE_DIR}/{hash}-{self._name}')
    os.makedirs(dir, exist_ok=True)

    shutil.copy(FPVM_HOME/'.config', Path(dir)/'config')
    os.system(f'git -C {FPVM_HOME} rev-parse HEAD > {Path(dir) / "GIT"}')
    if file is not None:
      return Path(dir) / file
    return Path(dir)

  def exists(self, name):
    dir = self.get()
    return os.path.isfile(dir / name)

  def __truediv__(self, name):
    return self.get(name)



def transform_binary(binary: Path, argv, patch_version: str='magic') -> Path:
    wrapped_binary = get_wrapped_binary(binary)
    patched_binary = get_patched_binary(wrapped_binary, binary, argv, patch_version)
    return patched_binary
    



# Given a binary, return a full path to a patched version of it
# @binary: A path to the binary we are interested in
# @argv: the arguments to the program required for profile-based patching
# @version: either 'magic' or 'trap'
def get_patched_binary(wrapped_binary: Path, original_binary: Path, argv, version: str='magic') -> Path:
  name = os.path.basename(original_binary)

  # ch = ContentHashDir(f'patch-profiled-{random.random()}-{name}')
  ch = ContentHashDir(f'patch-profiled-{name}')
  ch.file_input(wrapped_binary) # The key is simply the file itself.
  ch.file_input(original_binary) # The key is simply the file itself.
  for arg in argv:
      ch.string_input(arg)

  if version not in ['magic', 'trap']:
    raise ValueError(f'Invalid version, {version}')

  magic = name + '.magic'
  trap = name + '.trap'

  if not ch.exists(trap) or not ch.exists(magic):
    if os.system(f"fpvm_profile.sh {wrapped_binary} {original_binary} {' '.join(argv)}") != 0:
        print('failed to profile. aborting!')
        exit(-1)
    shutil.copy('patched_magic', ch.get(magic))
    shutil.copy('patched_trap', ch.get(trap))
    # Generate the patch in right place.
    # os.system(f'env FPVM_WRAP=disable fpvm_patch.sh -m -n -w {ch.get()} {wrapped_binary} >&2')
    # shutil.copy(ch.get('input.patched_magic'), ch.get(magic))
    # shutil.copy(ch.get('input.patched_trap'), ch.get(trap))

  return ch.get(f'{name}.{version}')








def get_additional_wrappers(wrap_list: Path, mode: str = 'reverse') -> Path:
  ch = ContentHashDir(f'additional_wrappers_{mode}')
  ch.file_input(wrap_list)

  so = ch / 'wrappers.so'

  os.system(f'cd {ch.get()} && wrap_dynamic_calls_{mode}.pl {wrap_list} wrap')

  # Generate a c file which pulls it all together
  with open(ch / 'wrap.c', 'w') as f:
    f.write(f'#define _GNU_SOURCE\n')
    f.write(f'#include <dlfcn.h>\n')
    f.write(f'#include <fpvm/fpvm_common.h>\n')
    f.write(f'#include "{ch / "wrap.h"}"\n')
    f.write(f'#include "{ch / "wrap.inc"}"\n')

    cmd = f'cd {ch.get()} && gcc -fPIC -shared -I {FPVM_HOME / "include"} -I {(FPVM_HOME / "include") / FPVM_ARCH} -o {so} wrap.c wrap.S'
    print("COMMAND = " + cmd)
    os.system(cmd)

  return so




def get_wrapped_binary(binary: Path, version: str='magic', mode: str = 'reverse') -> Path:
  name = os.path.basename(binary)
  # The wrapped binary is keyed on the hash of the patched binary

  ch = ContentHashDir(f'{mode}-wrap-{name}')
  ch.file_input(binary)

  get_additional_wrappers(WRAP_LIST)

  if mode == 'reverse':
    if not ch.exists(name):
      os.system(f'fpvm_wrap -o {ch/name} -f {WRAP_LIST} {binary}')
    return ch.get(name)


  raise ValueError('We only support the reverse mode in the fpvm script for now')




def run_fpvm_binary(bin: Path,
                    args: list[str],
                    use_fpvm: bool=True,
                    fpvm=FPVM_LOCATION,
                    logfile=None,
                    stdout=None,
                    stderr=None,
                    debug=False,
                    perf=False):
  # Called in a forked child where we can get rusage accurately
  def _run(bin: Path, args: list[str], send):
    usage = resource.getrusage(resource.RUSAGE_CHILDREN)

    env = os.environ.copy()
    if use_fpvm:
      env['LD_PRELOAD'] = str(fpvm) + ' ' + str(get_additional_wrappers(WRAP_LIST))
    if logfile is not None:
      env['FPVM_LOG_FILE'] = str(logfile)

    start = time.time()

    cmd = [bin, *args]

    # if perf_metrics:
    #     cmd = ['sudo', 'perf', 'record', '-g', '-F', 'max', 'env', f'LD_PRELOAD={env["LD_PRELOAD"]}'] + cmd
    #     print(cmd)
    #     del env['LD_PRELOAD']
    if debug:
        gdb_cmds = [
            '-iex', f'set env LD_PRELOAD={env["LD_PRELOAD"].replace(" ", ":")}', # LD_PRELOAD
            '-iex', f'handle SIGUSR2 nostop pass noprint', # 
            '-iex', f'handle SIGFPE nostop pass noprint', # 
            # '-iex', f'handle SIGTRAP nostop pass noprint', # 
            '-iex', f'set env FPVM_DISABLE_PTHREADS=y', # 
            '-iex', f'set env FPVM_AGGRESSIVE=y', # 
            '-iex', f'set env FPVM_AGGRESSIVE=y', # 
        ]
        cmd = ['gdb', *gdb_cmds] + cmd
        print(cmd)
        

    # print(env['LD_PRELOAD'])

    # print(cmd)
    # exit()

    proc = subprocess.Popen(
        cmd,
        stdout=stdout,
        stderr=stderr,
        env=env,
    )
    status = proc.wait()
    end = time.time()

    usage = resource.getrusage(resource.RUSAGE_CHILDREN)
    out = {}
    out["walltime"] = end - start
    out["time"] = usage.ru_utime + usage.ru_stime
    out["stime"] = usage.ru_stime
    out["utime"] = usage.ru_utime
    out["major"] = usage.ru_majflt
    out["minor"] = usage.ru_minflt
    out["maxrss"] = usage.ru_maxrss
    out["status"] = status
    send.send(out)

  # Create a data pipe that we can send data over
  recv, send = mp.Pipe(False)
  # Then, create a subprocess which calls _run and has a fresh RUSAGE_CHILDREN
  p = mp.Process(target=_run, args=(bin, args, send))
  p.start() # Start the process
  p.join() # And wait for it to finish
  # Finally, receive the data it sends
  return recv.recv()




# ===============================================================
# The following functions are callbacks from the argument parser:
# ===============================================================


# Run a binary with FPVM.
def cmd_run(args):
  bin = path_expand(args.binary)

  if not args.baseline:
    bin = transform_binary(bin, args.argv, 'magic')

  # exit()
  # Run the binary...
  out = run_fpvm_binary(bin,
                        args.argv,
                        # stdout=subprocess.DEVNULL
                        debug=args.debug,
                        perf=args.perf,
                        use_fpvm=not args.baseline)
  print(out)





# Wrap a binary with FPVM and print out where it lives
def cmd_wrap(args):
  bin = path_expand(args.binary)
  print(get_wrapped_binary(bin, 'magic', args.mode))










def get_telemetry(file: Path):
  t = {}
  with open(file) as f:
    for line in f:
      # Check if the line is even interesting
      m = re.match(r'^fpvm\s+info\(.*\):\s+telemetry:\s+(\S.*)$', line)
      if not m:
        continue
      # Cut the front off
      line = re.sub(r'^fpvm\s+info\(.*\):\s+telemetry:', '', line)

      for p in line.split(','):
        p = p.strip()
        p = re.sub(r'\(.*\)', '', p)
        match = re.match(r'^\d+', p)
        if match is None:
            continue
        val = int(match.group())
        remainder = p[len(match.group()):].strip().replace(' ', '_')
        t[remainder] = val
  return t



def get_performance(file: Path):
  metrics = []
  with open(file) as f:
    for line in f:
      # Check if the line is even interesting
      m = re.match(r'^fpvm\s+info\(.*\):\s+perf:\s+(\S.*) :\s+(\S.*)$', line)
      if not m:
        continue
      line = re.sub(r'^fpvm\s+info\(.*\):\s+perf:', '', line).strip()
      bits = line.split(' : ')

      m = {}
      m['name'] = bits[0].replace(' ', '_').strip()

      for p in bits[1].split(' '):
        name, val = p.split('=')
        m[name] = float(val)

      # Copmute avg, stddev ourselves just in case
      if m['count'] == 0:
        m['avg'] = 0.0;
        m['std'] = 0.0;
        m['min'] = 0;
        m['max'] = 0;
      else:
        m['avg'] = m['sum'] / m['count']
        m['std'] = math.sqrt(m['sum2'] / m['count'] - m['avg']*m['avg'])
      metrics.append(m)
  return metrics


def div_clamp(a, b):
  if b != 0:
    return a / b
  return 0


def analyze_benchmark_dir(name, output, run_name, run_idx):

  print(f"Analyzing benchmark={name}, output_dir={output}, run_name={run_name}, run_idx={run_idx}")

  output = Path(output).absolute()
  # Make sure the result dir is valid
  os.makedirs(output, exist_ok=True)

  usages = []
  amortized = []

  factor = f'{run_name}_{run_idx}'
  log = output / f'{factor}.fpvm_log'

  try:
    t = get_telemetry(log)
    pd.DataFrame([t]).to_csv(output / f'{factor}_telem.csv', index=False)

    perf_metrics = get_performance(log)
    pd.DataFrame(perf_metrics).to_csv(output / f'{factor}_perf.csv', index=False)

    # Create a nicer version of the perf data for use here:
    perf = {}
    for metric in perf_metrics:
      perf[metric['name']] = metric
    amor = {}

    numfpe = t.get('fp_traps', 0)
    numsinglestep = t.get('single_step_traps', 0)
    numcor = t.get('correctness_traps', 0)
    numfor = t.get('correctness_foreign_calls', 0)
    numinst = t.get('instructions_emulated', 0)
    numusefulinst = t.get('useful_instructions_emulated', 0)
    numextraneousinst = t.get('extraneous_instructions_emulated', 0)

    amor['name'] = name
    amor['run'] = run_name
    amor['hw'] = div_clamp(HW_TO_KERNEL_TIME*(numfpe-numsinglestep),numusefulinst);
    amor['kern'] = div_clamp(KERNEL_TO_USER_TIME*(numfpe-numsinglestep),numusefulinst);
    amor['decache'] = div_clamp(perf['decode_cache']['sum'],numusefulinst);
    amor['decode'] = div_clamp(perf['decoder']['sum'],numusefulinst);
    amor['bind'] = div_clamp(perf['bind']['sum'],numusefulinst);
    amor['emul'] = div_clamp(perf['emulate']['sum'],numusefulinst);
    amor['gc'] = div_clamp(perf['garbage_collector']['sum'],numusefulinst);
    amor['fcall'] = div_clamp(perf['foreign_call']['sum']+CALL_WRAP_TIME*numfor,numusefulinst);
    amor['corr'] = div_clamp(perf['correctness']['sum']+(HW_TO_KERNEL_TIME+KERNEL_TO_USER_TIME)*numcor,numusefulinst);

    amor['set_ts'] = div_clamp(perf['set_ts']['sum'],numusefulinst);
    amor['clear_ts'] = div_clamp(perf['clear_ts']['sum'],numusefulinst);
    amor['mark_in_signal'] = div_clamp(perf['mark_in_signal']['sum'],numusefulinst);
    amor['single_step_hw'] = div_clamp(HW_TO_KERNEL_TIME*(numsinglestep),numusefulinst);
    amor['single_step_kern'] = div_clamp(KERNEL_TO_USER_TIME*(numsinglestep),numusefulinst);

    total_names = ['hw','kern','decache','decode','bind','emul','gc','fcall','corr','set_ts','clear_ts','mark_in_signal','single_step_hw','single_step_kern']
    amor['total'] = sum([(amor[name] if name in amor.keys() else 0.0) for name in total_names]);

    amortized.append(amor)

  except Exception as e:
    print(e)
    print("failed to get amortized timing information. Maybe you turned it off?")
    raise e

  amor_csv_path = output / f'{run_name}_amortized.csv'
  print(f"Creating {amor_csv_path} out of {amortized}")
  pd.DataFrame(amortized).to_csv(amor_csv_path, index=False)
  # Use peter's script to generate the graph inputs
  os.system(f'cd {output} && generate_graph_inputs.pl {name} {factor} {HW_TO_KERNEL_TIME} {KERNEL_TO_USER_TIME} {CALL_WRAP_TIME} baseline_0.fpvm_log {log}')
  # ...

def run_benchmark_binary(name, output, binary, argv, fpvm=FPVM_LOCATION, count=1, baseline=True, only_baseline=False):
  bin = path_expand(binary)

  name = name or os.path.basename(bin)

  output = Path(output).absolute()
  # Make sure the result dir is valid
  os.makedirs(output, exist_ok=True)

  # Save the .config that FPVM was compiled with
  shutil.copy(FPVM_HOME/'.config', output/'config')
  shutil.copy(fpvm, output/'fpvm.so')
  # Save the git hash of the most recent commit
  os.system(f'git -C {FPVM_HOME} rev-parse HEAD > {output / "GIT"}')

  # Construct the environ the binary should be run with
  fpvm_env = os.environ.copy()
  print('running with fpvm at', fpvm)
  fpvm_env['LD_PRELOAD'] = output / 'fpvm.so'

  runs = []

  if baseline:
      runs.append(('baseline', binary, os.environ.copy()))
  runs.append(('fpvm_magic', transform_binary(binary, argv, 'magic'), fpvm_env))

  for run_name, bin, env in runs:
    print(run_name)
    usages = []
    amortized = []
    use_fpvm = run_name != 'baseline'
    for run_idx in range(count):
      factor = f'{run_name}_{run_idx}'
      log = output / f'{factor}.fpvm_log'
      print(f'Running {factor} into {log}')
      with open(output / f'{factor}.ENV', 'w') as e:
        for var in env:
          e.write(f'{var}={env[var]}\n')
      with open(output / f'{factor}.stdout', 'w') as stdout:
        with open(output / f'{factor}.stderr', 'w') as stderr:
          usage = run_fpvm_binary(bin,
                                  argv,
                                  use_fpvm=use_fpvm,
                                  fpvm=output/'fpvm.so',
                                  logfile=log,
                                  stdout=stdout,
                                  stderr=stderr)
      print(f'    time: {usage["time"]}s')
      with open(log, "a") as f:
        f.write(f'fpvm time: real {usage["time"]:.4f} user {usage["utime"]:.4f} sys {usage["stime"]:.4f}\n')


      # If this run is using FPVM, make sure to record telemetry, perf, and amortized metrics.
      if use_fpvm:
        try:
          t = get_telemetry(log)
          pd.DataFrame([t]).to_csv(output / f'{factor}_telem.csv', index=False)

          perf_metrics = get_performance(log)
          pd.DataFrame(perf_metrics).to_csv(output / f'{factor}_perf.csv', index=False)

          # Create a nicer version of the perf data for use here:
          perf = {}
          for metric in perf_metrics:
            perf[metric['name']] = metric
          amor = {}

          numfpe = t.get('fp_traps', 0)
          numsinglestep = t.get('single_step_traps', 0)
          numcor = t.get('correctness_traps', 0)
          numfor = t.get('correctness_foreign_calls', 0)
          numinst = t.get('instructions_emulated', 0)
          numusefulinst = t.get('useful_instructions_emulated', 0)
          numextraneousinst = t.get('extraneous_instructions_emulated', 0)

          amor['name'] = name
          amor['run'] = run_name
          amor['hw'] = div_clamp(HW_TO_KERNEL_TIME*(numfpe-numsinglestep),numusefulinst);
          amor['kern'] = div_clamp(KERNEL_TO_USER_TIME*(numfpe-numsinglestep),numusefulinst);
          amor['decache'] = div_clamp(perf['decode_cache']['sum'],numusefulinst);
          amor['decode'] = div_clamp(perf['decoder']['sum'],numusefulinst);
          amor['bind'] = div_clamp(perf['bind']['sum'],numusefulinst);
          amor['emul'] = div_clamp(perf['emulate']['sum'],numusefulinst);
          amor['gc'] = div_clamp(perf['garbage_collector']['sum'],numusefulinst);
          amor['fcall'] = div_clamp(perf['foreign_call']['sum']+CALL_WRAP_TIME*numfor,numusefulinst);
          amor['corr'] = div_clamp(perf['correctness']['sum']+(HW_TO_KERNEL_TIME+KERNEL_TO_USER_TIME)*numcor,numusefulinst);

          amor['set_ts'] = div_clamp(perf['set_ts']['sum'],numusefulinst);
          amor['clear_ts'] = div_clamp(perf['clear_ts']['sum'],numusefulinst);
          amor['mark_in_signal'] = div_clamp(perf['mark_in_signal']['sum'],numusefulinst);
          amor['single_step_hw'] = div_clamp(HW_TO_KERNEL_TIME*(2*numsinglestep),numusefulinst); # We fault once per single step: initial SIGFPE then again for a SIGTRAP
          amor['single_step_kern'] = div_clamp(KERNEL_TO_USER_TIME*(2*numsinglestep),numusefulinst);

          total_names = ['hw','kern','decache','decode','bind','emul','gc','fcall','corr','set_ts','clear_ts','mark_in_signal','single_step_hw','single_step_kern']
          amor['total'] = sum([(amor[name] if name in amor.keys() else 0.0) for name in total_names]);

          amortized.append(amor)
        except Exception as e:
          print(e)
          print("failed to get amortized timing information. Maybe you turned it off?")

      usages.append(usage)


    pd.DataFrame(usages).to_csv(output / f'{run_name}_rusage.csv', index=False)
    if use_fpvm:
      pd.DataFrame(amortized).to_csv(output / f'{run_name}_amortized.csv', index=False)
      # Use peter's script to generate the graph inputs
      os.system(f'cd {output} && generate_graph_inputs.pl {name} {factor} {HW_TO_KERNEL_TIME} {KERNEL_TO_USER_TIME} {CALL_WRAP_TIME} baseline_0.fpvm_log {log}')
  # ...

def cmd_benchmark(args):
  run_benchmark_binary(args.name,
                       args.output,
                       args.binary,
                       args.argv,
                       fpvm=args.fpvm,
                       count=args.count,
                       baseline=True)

def cmd_analyze_benchmark(args):
  analyze_benchmark_dir(args.name,
                        args.output,
                        'fpvm_magic',
                        0)


# build FPVM for all the different configurations using test/sweep/base_config (if needed)
#    Sweep these configurations:
#     - Trap short circuiting     (I think the kernel module can be inserted, but
#                                  FPVM will configure it if needed)
#     - Instruction Sequence      (This could honestly just be an environment variable)
#     - Correction trap via calls (Make this script be able to enable/disable this)
# run the benchmark against all those FPVM configs, and save useful data
def cmd_sweep(args):
    # for each of the configurations, keyed with the git revision...
    # create a cache directory, and build FPVM with that configuration if needed.
    # run the binary, saving results as needed.
    # ...
    # This is where cmake would be awesome.
    # ...
    # We need to modify .config in the filesystem with the configuration of the run.
    # Then, we need to run the menuconfig to sync the .config and the autoconf.h

    all_options = []

    with open(f'{FPVM_HOME}/Kconfig', 'r') as f:
        for line in f:
            stripped = line.strip()
            words = stripped.split(' ')
            if len(words) != 2:
                continue
            if words[0] != 'config':
                continue

            name = words[1]
            full_name = 'CONFIG_' + name
            all_options.append(full_name)

    # First things first, this is the baseline configuration we will use for each compilation
    base_config = [
        'CONFIG_ARCH_X64=y',
        'CONFIG_INSTR_SEQ_EMULATION=y',
        #'CONFIG_MAGIC_CORRECTNESS_TRAP=y', # TODO: used to be an under-test
    ]

    telemetry_configs = [
        # ('basic_timing', [
        #     # 'CONFIG_TELEMETRY=y',
        #     # "CONFIG_TELEMETRY_PROMOTIONS=y",
        #     # "CONFIG_TELEMETRY_PERIOD=0",
        # ]),
         ('telem_perf', [
             "CONFIG_TELEMETRY=y",
        #     "CONFIG_TELEMETRY_PROMOTIONS=y",
             "CONFIG_TELEMETRY_PERIOD=0",
             "CONFIG_PERF_STATS=y",
             "CONFIG_PERF_STATS_PERIOD=0",
        #     # "CONFIG_INSTR_TRACES=n",
        #     # "CONFIG_INSTR_TRACES_PERIOD=0"
         ]),
        ('instruction_traces', [
            # "CONFIG_TELEMETRY=n",
            # "CONFIG_TELEMETRY_PROMOTIONS=n",
            # "CONFIG_TELEMETRY_PERIOD=0",
            # "CONFIG_PERF_STATS=n",
            # "CONFIG_PERF_STATS_PERIOD=0",
            "CONFIG_INSTR_TRACES=y",
            "CONFIG_INSTR_TRACES_PERIOD=0"
        ]),
    ]

    alt_math_configs = [
        # Run boxed first so we can see results quicker
        # ('boxed', ['CONFIG_ALT_MATH_BOXED_IEEE=y']),
        # Then run vanilla for the information it provides
        # ('vanilla', ['CONFIG_ALT_MATH_VANILLA=y']),
        # ('mpfr', [
        #     'CONFIG_ALT_MATH_MPFR=y',
        #     'CONFIG_MPFR_PRECISION=200'
        # ]),
        ('teeny', ['CONFIG_ALT_MATH_TEENY=y']),
    ]


    under_test = [
        #'CONFIG_INSTR_SEQ_EMULATION=y',
        #'CONFIG_TRAP_SHORT_CIRCUITING=y',
    ]


    perm_configs = [] # (name, [config...])



    for L in range(len(under_test) + 1):
        if L == 0:
            continue
        for perm in itertools.combinations(under_test, L):
            perm = list(perm)
            perm_name = '-'.join(map(lambda x: x.replace('CONFIG_', '').lower().split('=')[0], perm))
            perm_configs.append((perm_name, perm))

    perm_configs.append(('no_accel', []))

    all_configs = [] # (name, [config...])

    for alt_name, alt_config in alt_math_configs:
        for perm_name, perm_config in perm_configs:
            for telem_name, telem_config in telemetry_configs:
                name = f'{alt_name}/{telem_name}/{perm_name}/'
                all_configs.append((name, base_config + alt_config + telem_config + perm_config))


    # backup the original .config that the user was using
    print("Backing up original `.config`. \033[5;41mDO NOT\033[0m attempt to change anything about FPVM's configuration OR attempt to compile FPVM while this script is running!")
    os.system(f'mv {FPVM_HOME}/.config {FPVM_HOME}/.config.bak')

    print('configs: ', len(all_configs))
    for i, (name, config) in enumerate(all_configs):
        print(f'\033[32m[PROGRESS: {i + 1}/{len(all_configs)}]\033[0m')
        # the configuration, as a dictionary
        cfg = {}

        for c in config:
            option = c.split('=')[0]
            val = c.split('=')[1]
            cfg[option] = val
        
        config_path = f'{FPVM_HOME}/.config'
        # print('Building fpvm for configuration', name)
        # Apply the configuration file
        with open(config_path, 'w') as file:
            for option in all_options:
                if option in cfg:
                    file.write(f'{option}={cfg[option]}\n')
                else:
                    file.write(f'# {option} is not set\n')

        build_dir = f'{FPVM_HOME}/build-sweep/{name}'
        os.system(f'mkdir -p {build_dir}')

        # Reconfigure
        os.system(f'make --no-print-directory -C {FPVM_HOME} reconfig')
        # Compile FPVM, building into the new build dir we made.
        os.system(f'make --no-print-directory -C {FPVM_HOME} -j BUILD={build_dir}')

        bin = path_expand(args.binary)
        bin_name = os.path.basename(bin)
        output_dir = f'./sweep-results/{bin_name}/{name}/'
        run_benchmark_binary(bin_name, output_dir, bin, args.argv, fpvm=f'{build_dir}/fpvm.so', baseline=True, count=1)

    print("Restoring original `.config`")
    os.system(f'mv {FPVM_HOME}/.config.bak {FPVM_HOME}/.config')
    os.system(f'make --no-print-directory -C {FPVM_HOME} reconfig')
    print('\033[32mDONE with the sweep!\033[0m You can now safely work on FPVM')





def clear_cache(args):
  # Simply delete where the cache is
  shutil.rmtree(CACHE_DIR, ignore_errors=True)




# ===============================================================
# Arg parsing and dispatch below:
# ===============================================================


if __name__ == '__main__':

  parser = argparse.ArgumentParser(
    prog='FPVM',
    description='The floating point virtual machine')

  parser.add_argument('--cachedir', help='Where the cache should be located', required=False, default=CACHE_DIR)
  parser.add_argument('--fpvm', help='Path to FPVM', required=False, default=FPVM_LOCATION)
  parser.add_argument('--wrap-list', help='The wrap list to use when generating wrappers', default=FPVM_HOME / 'src/wrap.list')

  sub = parser.add_subparsers(required=True, title='action')

  # The run subcommand
  p = sub.add_parser('run', help='run a binary')
  p.add_argument('-o', help='Optional argument')
  p.add_argument('--baseline', help='Run the original binary w/ timing', action='store_true')
  p.add_argument('--nopatch', help='Dont patch the binary', action='store_true')
  p.add_argument('--onlywrap', help='Only wrap the binary', action='store_true')
  p.add_argument('--debug', help='Debug the binary in GDB', action='store_true')
  p.add_argument('--perf', help='Profile the binary in perf', action='store_true')
  p.add_argument('binary', help='Binary to run')
  p.add_argument('argv', nargs=argparse.REMAINDER, help='Arguments to the binary')
  p.set_defaults(func=cmd_run)

  # The benchmark subcommand
  p = sub.add_parser('benchmark', help='benchmark FPVM\'s overhead on a binary')
  p.add_argument('-c', '--count', type=int, help='How many runs', default=1)
  p.add_argument('--name', type=str, help='Name of the benchmark run (Defaults to the name of the binary)')
  p.add_argument('-o', '--output', help='Directory where outputs should be written', required=True)
  p.add_argument('binary', help='Binary to run')
  p.add_argument('argv', nargs=argparse.REMAINDER, help='Arguments to the binary')
  p.set_defaults(func=cmd_benchmark)

  p = sub.add_parser('analyze', help='re-run analysis script on benchmark output')
  p.add_argument('name', help='Name of the benchmark')
  p.add_argument('output', help='Directory where benchmark outputs were written')
  p.set_defaults(func=cmd_analyze_benchmark)

  # # The patch subcommand
  # p = sub.add_parser('patch', help='patch a binary')
  # p.add_argument('-o', '--output', help='output binary', default='fpvm.out')
  # p.add_argument('binary', help='Binary to patch')
  # p.set_defaults(func=cmd_patch)


  # The wrap subcommand
  p = sub.add_parser('wrap', help='wrap the symbols in a binary')
  p.add_argument('-o', '--output', help='output binary', default='fpvm.out')
  p.add_argument('-m', '--mode', help='The wrap mode to use (forward/reverse)', default='reverse')
  p.add_argument('-s', dest='symbols', default="", help="comma-seperated list of symbols")
  p.add_argument('-f', '--from-file', help='file which contains a symbol on each line')
  p.add_argument('binary', help='Binary to wrap')
  p.set_defaults(func=cmd_wrap)


  # The sweep command
  p = sub.add_parser('sweep', help='Run a program, sweeping the configurations for the accel paper')
  p.add_argument('binary', help='Binary to run')
  p.add_argument('argv', nargs=argparse.REMAINDER, help='Arguments to the binary')
  p.set_defaults(func=cmd_sweep)

  # The clear-cache command
  p = sub.add_parser('clear-cache', help='Delete the FPVM cache directory')
  p.set_defaults(func=clear_cache)

  # Parse the commands
  args = parser.parse_args()

  if args.fpvm is None:
    print('Could not find an fpvm.so installed. Aborting')
    exit(-1)

  # If fpvm is found (or provided), make it an absolute path
  args.fpvm = os.path.realpath(args.fpvm)
  FPVM_LOCATION = args.fpvm
  WRAP_LIST = args.wrap_list
  CACHE_DIR = os.path.realpath(os.path.expanduser(args.cachedir))


  if hasattr(args, 'func'):
    args.func(args)
